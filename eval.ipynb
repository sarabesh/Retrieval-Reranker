{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43ac024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed:\n",
    "# !pip install numpy tqdm\n",
    "\n",
    "import json, pathlib, math\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "644cf8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded queries: 1,000 | qrels: 1,000\n"
     ]
    }
   ],
   "source": [
    "# Point to your prepared dataset folder\n",
    "DATA_DIR = \"prepared/msmarco-dev-subset-1000-plus-50000-neg\"   # or \"prepared/msmarco-dev\"\n",
    "\n",
    "# Load queries.tsv\n",
    "queries: Dict[str, str] = {}\n",
    "with open(pathlib.Path(DATA_DIR) / \"queries.tsv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        qid, qtext = line.rstrip(\"\\n\").split(\"\\t\", 1)\n",
    "        queries[qid] = qtext\n",
    "\n",
    "# Load qrels.tsv  (qid \\t 0 \\t docid \\t rel)\n",
    "qrels: Dict[str, Dict[str, int]] = {}\n",
    "with open(pathlib.Path(DATA_DIR) / \"qrels.tsv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        qid, _, docid, rel = line.strip().split(\"\\t\")\n",
    "        qrels.setdefault(qid, {})[docid] = int(rel)\n",
    "\n",
    "print(f\"Loaded queries: {len(queries):,} | qrels: {len(qrels):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "895f677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k(ranked: List[str], truth: Dict[str,int], k=10) -> float:\n",
    "    dcg = 0.0\n",
    "    for i, doc_id in enumerate(ranked[:k], start=1):\n",
    "        rel = truth.get(doc_id, 0)\n",
    "        if rel > 0:\n",
    "            dcg += rel / math.log2(i + 1)\n",
    "    idcg = 0.0\n",
    "    for i, rel in enumerate(sorted(truth.values(), reverse=True)[:k], start=1):\n",
    "        idcg += rel / math.log2(i + 1)\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "def mrr_at_k(ranked: List[str], truth: Dict[str,int], k=10) -> float:\n",
    "    for i, doc_id in enumerate(ranked[:k], start=1):\n",
    "        if truth.get(doc_id, 0) > 0:\n",
    "            return 1.0 / i\n",
    "    return 0.0\n",
    "\n",
    "def recall_at_k(ranked: List[str], truth: Dict[str,int], k=10) -> float:\n",
    "    rel_docs = [d for d, r in truth.items() if r > 0]\n",
    "    if not rel_docs:\n",
    "        return 0.0\n",
    "    hits = sum(1 for d in ranked[:k] if d in truth and truth[d] > 0)\n",
    "    return hits / len(rel_docs)\n",
    "\n",
    "def precision_at_k(ranked: List[str], truth: Dict[str,int], k=10) -> float:\n",
    "    if k == 0:\n",
    "        return 0.0\n",
    "    hits = sum(1 for d in ranked[:k] if truth.get(d, 0) > 0)\n",
    "    return hits / k\n",
    "\n",
    "def average_precision_at_k(ranked: List[str], truth: Dict[str,int], k=10) -> float:\n",
    "    rel_docs = [d for d, r in truth.items() if r > 0]\n",
    "    if not rel_docs:\n",
    "        return 0.0\n",
    "    ap, hits = 0.0, 0\n",
    "    for i, d in enumerate(ranked[:k], start=1):\n",
    "        if truth.get(d, 0) > 0:\n",
    "            hits += 1\n",
    "            ap += hits / i\n",
    "    return ap / len(rel_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff39b884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded results for 1000 queries\n"
     ]
    }
   ],
   "source": [
    "RUNS_DIR = \"runs\"\n",
    "json_path = pathlib.Path(RUNS_DIR) / f\"{pathlib.Path(DATA_DIR).name}_dense_top10.json\"\n",
    "\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    results = json.load(f)  # dict[qid] = [doc_ids]\n",
    "\n",
    "print(\"Loaded results for\", len(results), \"queries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "176a3621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 1000 queries\n",
      "nDCG@10     = 0.9217\n",
      "MRR@10      = 0.9037\n",
      "Recall@10   = 0.9828\n",
      "Precision@10= 0.1034\n",
      "MAP@10      = 0.9004\n"
     ]
    }
   ],
   "source": [
    "qids_eval = [qid for qid in results if qid in qrels]\n",
    "\n",
    "ndcg = np.mean([ndcg_at_k(results[qid], qrels[qid], k=10) for qid in qids_eval])\n",
    "mrr  = np.mean([mrr_at_k(results[qid], qrels[qid], k=10) for qid in qids_eval])\n",
    "rec  = np.mean([recall_at_k(results[qid], qrels[qid], k=10) for qid in qids_eval])\n",
    "prec = np.mean([precision_at_k(results[qid], qrels[qid], k=10) for qid in qids_eval])\n",
    "mapk = np.mean([average_precision_at_k(results[qid], qrels[qid], k=10) for qid in qids_eval])\n",
    "\n",
    "print(f\"Evaluated on {len(qids_eval)} queries\")\n",
    "print(f\"nDCG@10     = {ndcg:.4f}\")\n",
    "print(f\"MRR@10      = {mrr:.4f}\")\n",
    "print(f\"Recall@10   = {rec:.4f}\")\n",
    "print(f\"Precision@10= {prec:.4f}\")\n",
    "print(f\"MAP@10      = {mapk:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
