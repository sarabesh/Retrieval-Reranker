{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a9602d1",
   "metadata": {},
   "source": [
    "Notebook to download dataset and prepare it in format suitable for testing and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93371b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarab\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\beir\\util.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# If needed:\n",
    "# !pip install beir tqdm\n",
    "\n",
    "import os, json, pathlib\n",
    "from tqdm import tqdm\n",
    "from beir import util\n",
    "from beir.datasets.data_loader import GenericDataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "557d2384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885e5891e66249b2a4d5179e77a500e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "datasets\\msmarco.zip:   0%|          | 0.00/1.01G [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded & extracted to: datasets\\msmarco\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"datasets\"  # where to store raw BEIR data\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "dataset = \"msmarco\"  # BEIR's MSMARCO Passage\n",
    "url = f\"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{dataset}.zip\"\n",
    "\n",
    "data_path = util.download_and_unzip(url, DATA_DIR)\n",
    "print(\"Downloaded & extracted to:\", data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bf9a03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7afaec1ba86d4c34ab3318993b3bee28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8841823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus docs: 8,841,823\n",
      "Queries total: 6,980\n",
      "Queries with qrels: 6,980\n"
     ]
    }
   ],
   "source": [
    "corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split=\"dev\")\n",
    "print(f\"Corpus docs: {len(corpus):,}\")\n",
    "print(f\"Queries total: {len(queries):,}\")\n",
    "print(f\"Queries with qrels: {len(qrels):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37b3955a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving corpus.jsonl: 100%|██████████| 8841823/8841823 [01:22<00:00, 106890.29it/s]\n",
      "Saving queries.tsv: 100%|██████████| 6980/6980 [00:00<00:00, 774278.44it/s]\n",
      "Saving qrels.tsv: 100%|██████████| 6980/6980 [00:00<00:00, 631089.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: prepared/msmarco-dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "OUT_DIR = \"prepared/msmarco-dev\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# 3a) Save corpus.jsonl\n",
    "with open(pathlib.Path(OUT_DIR) / \"corpus.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for doc_id, fields in tqdm(corpus.items(), desc=\"Saving corpus.jsonl\"):\n",
    "        rec = {\n",
    "            \"_id\": doc_id,\n",
    "            \"title\": fields.get(\"title\", \"\"),\n",
    "            \"text\": fields.get(\"text\", \"\")\n",
    "        }\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# 3b) Save queries.tsv (qid \\t query)  -- fixed\n",
    "with open(pathlib.Path(OUT_DIR) / \"queries.tsv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for qid, text in tqdm(queries.items(), desc=\"Saving queries.tsv\"):\n",
    "        clean_text = text.replace(\"\\n\", \" \").strip()  # precompute to avoid backslash in f-string\n",
    "        f.write(f\"{qid}\\t{clean_text}\\n\")\n",
    "\n",
    "# 3c) Save qrels.tsv (qid \\t 0 \\t docid \\t rel)\n",
    "with open(pathlib.Path(OUT_DIR) / \"qrels.tsv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for qid, rels in tqdm(qrels.items(), desc=\"Saving qrels.tsv\"):\n",
    "        for doc_id, rel in rels.items():\n",
    "            f.write(f\"{qid}\\t0\\t{doc_id}\\t{rel}\\n\")\n",
    "\n",
    "print(\"Saved to:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd5d5132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving subset corpus.jsonl: 100%|██████████| 211/211 [00:00<00:00, 70338.43it/s]\n",
      "Saving subset queries.tsv: 100%|██████████| 200/200 [00:00<00:00, 199823.92it/s]\n",
      "Saving subset qrels.tsv: 100%|██████████| 200/200 [00:00<00:00, 198265.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved subset to: prepared/msmarco-dev-subset-200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a subset with the first N queries that have qrels\n",
    "N = 200  # tweak as needed\n",
    "subset_qids = [qid for qid in qrels.keys()][:N]\n",
    "\n",
    "# Collect gold doc IDs from qrels\n",
    "subset_gold_doc_ids = set()\n",
    "for qid in subset_qids:\n",
    "    subset_gold_doc_ids.update(qrels[qid].keys())\n",
    "\n",
    "SUB_DIR = f\"prepared/msmarco-dev-subset-{N}\"\n",
    "os.makedirs(SUB_DIR, exist_ok=True)\n",
    "\n",
    "# 4a) Save subset corpus.jsonl\n",
    "with open(pathlib.Path(SUB_DIR) / \"corpus.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for doc_id in tqdm(subset_gold_doc_ids, desc=\"Saving subset corpus.jsonl\"):\n",
    "        fields = corpus[doc_id]\n",
    "        rec = {\n",
    "            \"_id\": doc_id,\n",
    "            \"title\": fields.get(\"title\", \"\"),\n",
    "            \"text\": fields.get(\"text\", \"\")\n",
    "        }\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# 4b) Save subset queries.tsv  -- fixed\n",
    "with open(pathlib.Path(SUB_DIR) / \"queries.tsv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for qid in tqdm(subset_qids, desc=\"Saving subset queries.tsv\"):\n",
    "        clean_text = queries[qid].replace(\"\\n\", \" \").strip()\n",
    "        f.write(f\"{qid}\\t{clean_text}\\n\")\n",
    "\n",
    "# 4c) Save subset qrels.tsv\n",
    "with open(pathlib.Path(SUB_DIR) / \"qrels.tsv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for qid in tqdm(subset_qids, desc=\"Saving subset qrels.tsv\"):\n",
    "        for doc_id, rel in qrels[qid].items():\n",
    "            f.write(f\"{qid}\\t0\\t{doc_id}\\t{rel}\\n\")\n",
    "\n",
    "print(\"Saved subset to:\", SUB_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ff74fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving subset corpus.jsonl: 100%|██████████| 1053/1053 [00:00<00:00, 54111.76it/s]\n",
      "Saving subset queries.tsv: 100%|██████████| 1000/1000 [00:00<00:00, 667139.18it/s]\n",
      "Saving subset qrels.tsv: 100%|██████████| 1000/1000 [00:00<00:00, 396662.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved subset to: prepared/msmarco-dev-subset-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a subset with the first N queries that have qrels\n",
    "N = 1000  # tweak as needed\n",
    "subset_qids = [qid for qid in qrels.keys()][:N]\n",
    "\n",
    "# Collect gold doc IDs from qrels\n",
    "subset_gold_doc_ids = set()\n",
    "for qid in subset_qids:\n",
    "    subset_gold_doc_ids.update(qrels[qid].keys())\n",
    "\n",
    "SUB_DIR = f\"prepared/msmarco-dev-subset-{N}\"\n",
    "os.makedirs(SUB_DIR, exist_ok=True)\n",
    "\n",
    "# 4a) Save subset corpus.jsonl\n",
    "with open(pathlib.Path(SUB_DIR) / \"corpus.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for doc_id in tqdm(subset_gold_doc_ids, desc=\"Saving subset corpus.jsonl\"):\n",
    "        fields = corpus[doc_id]\n",
    "        rec = {\n",
    "            \"_id\": doc_id,\n",
    "            \"title\": fields.get(\"title\", \"\"),\n",
    "            \"text\": fields.get(\"text\", \"\")\n",
    "        }\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# 4b) Save subset queries.tsv  -- fixed\n",
    "with open(pathlib.Path(SUB_DIR) / \"queries.tsv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for qid in tqdm(subset_qids, desc=\"Saving subset queries.tsv\"):\n",
    "        clean_text = queries[qid].replace(\"\\n\", \" \").strip()\n",
    "        f.write(f\"{qid}\\t{clean_text}\\n\")\n",
    "\n",
    "# 4c) Save subset qrels.tsv\n",
    "with open(pathlib.Path(SUB_DIR) / \"qrels.tsv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for qid in tqdm(subset_qids, desc=\"Saving subset qrels.tsv\"):\n",
    "        for doc_id, rel in qrels[qid].items():\n",
    "            f.write(f\"{qid}\\t0\\t{doc_id}\\t{rel}\\n\")\n",
    "\n",
    "print(\"Saved subset to:\", SUB_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ce4e33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries kept: 1000\n",
      "Gold docs in subset: 1,053\n",
      "Sampling negatives from pool of 8,840,770 docs...\n",
      "Final subset corpus size: 51,053 (gold + negatives)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving subset corpus.jsonl: 100%|██████████| 51053/51053 [00:00<00:00, 91280.06it/s]\n",
      "Saving subset queries.tsv: 100%|██████████| 1000/1000 [00:00<00:00, 396025.30it/s]\n",
      "Saving subset qrels.tsv: 100%|██████████| 1000/1000 [00:00<00:00, 500215.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved subset to: prepared/msmarco-dev-subset-1000-plus-50000-neg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, json, pathlib, random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---- Config ----\n",
    "N = 1000              # number of queries to keep\n",
    "M_NEG = 50_000        # number of extra non-gold docs to add\n",
    "SEED = 42             # for reproducibility\n",
    "SUB_DIR = f\"prepared/msmarco-dev-subset-{N}-plus-{M_NEG}-neg\"\n",
    "os.makedirs(SUB_DIR, exist_ok=True)\n",
    "random.seed(SEED)\n",
    "\n",
    "# 1) Keep first N queries that have qrels\n",
    "subset_qids = list(qrels.keys())[:N]\n",
    "\n",
    "# 2) Collect all gold doc IDs from qrels for those queries\n",
    "gold_doc_ids = set()\n",
    "for qid in subset_qids:\n",
    "    gold_doc_ids.update(qrels[qid].keys())\n",
    "\n",
    "print(f\"Queries kept: {len(subset_qids)}\")\n",
    "print(f\"Gold docs in subset: {len(gold_doc_ids):,}\")\n",
    "\n",
    "# 3) Sample M_NEG extra non-gold docs from the full corpus\n",
    "all_doc_ids = list(corpus.keys())\n",
    "candidate_negs = [d for d in all_doc_ids if d not in gold_doc_ids]\n",
    "print(f\"Sampling negatives from pool of {len(candidate_negs):,} docs...\")\n",
    "\n",
    "if M_NEG > len(candidate_negs):\n",
    "    print(f\"Requested {M_NEG} negatives, but only {len(candidate_negs)} available. Using all.\")\n",
    "    sampled_negs = candidate_negs\n",
    "else:\n",
    "    sampled_negs = random.sample(candidate_negs, M_NEG)\n",
    "\n",
    "# Final doc set = gold ∪ sampled negatives\n",
    "subset_doc_ids = list(gold_doc_ids.union(sampled_negs))\n",
    "print(f\"Final subset corpus size: {len(subset_doc_ids):,} (gold + negatives)\")\n",
    "\n",
    "# 4a) Save subset corpus.jsonl\n",
    "with open(pathlib.Path(SUB_DIR) / \"corpus.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for doc_id in tqdm(subset_doc_ids, desc=\"Saving subset corpus.jsonl\"):\n",
    "        fields = corpus[doc_id]\n",
    "        rec = {\n",
    "            \"_id\": doc_id,\n",
    "            \"title\": fields.get(\"title\", \"\"),\n",
    "            \"text\": fields.get(\"text\", \"\")\n",
    "        }\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# 4b) Save subset queries.tsv (N queries)\n",
    "with open(pathlib.Path(SUB_DIR) / \"queries.tsv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for qid in tqdm(subset_qids, desc=\"Saving subset queries.tsv\"):\n",
    "        clean_text = queries[qid].replace(\"\\n\", \" \").strip()\n",
    "        f.write(f\"{qid}\\t{clean_text}\\n\")\n",
    "\n",
    "# 4c) Save subset qrels.tsv (unchanged labels, only for kept queries)\n",
    "with open(pathlib.Path(SUB_DIR) / \"qrels.tsv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for qid in tqdm(subset_qids, desc=\"Saving subset qrels.tsv\"):\n",
    "        for doc_id, rel in qrels[qid].items():\n",
    "            f.write(f\"{qid}\\t0\\t{doc_id}\\t{rel}\\n\")\n",
    "\n",
    "print(\"Saved subset to:\", SUB_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fa24c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full set samples:\n",
      "1825845 … Caledonia Country Club is located at 303 Park Place in the Village of Caledonia, …\n",
      "4944092 … Seven key provisions of the revised scaffolding standard: A Ã¢-mid rails must be …\n",
      "Query row: 300674\thow many years did william bradford serve as governor of plymouth colony?\n",
      "Query row: 125705\tdefine preventive\n",
      "Qrels row: 300674\t0\t7067032\t1\n",
      "Qrels row: 125705\t0\t7067056\t1\n"
     ]
    }
   ],
   "source": [
    "# Read a couple of lines back to verify\n",
    "import itertools, json\n",
    "\n",
    "print(\"\\nFull set samples:\")\n",
    "with open(pathlib.Path(SUB_DIR) / \"corpus.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in itertools.islice(f, 2):\n",
    "        print(json.loads(line)[\"_id\"], \"…\", json.loads(line)[\"text\"][:80].replace(\"\\n\",\" \"), \"…\")\n",
    "\n",
    "with open(pathlib.Path(SUB_DIR) / \"queries.tsv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in itertools.islice(f, 2):\n",
    "        print(\"Query row:\", line.strip())\n",
    "\n",
    "with open(pathlib.Path(SUB_DIR) / \"qrels.tsv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in itertools.islice(f, 2):\n",
    "        print(\"Qrels row:\", line.strip())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
